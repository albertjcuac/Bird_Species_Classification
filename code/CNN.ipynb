{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMPORTES Y DEFINICION DE ALGUNAS VARIABLES NECESARIAS","metadata":{}},{"cell_type":"code","source":"import pytorch_lightning as pl\nimport pandas as pd\nimport cv2\nimport os \nfrom torch import nn\nfrom torch.utils.data import Dataset ,DataLoader\nimport numpy as np\nimport torch\nfrom sklearn.model_selection import train_test_split \nimport torchvision\nimport torchmetrics as metrics\nimport matplotlib.image as mpimg\nfrom PIL import Image\nimport glob\nimport matplotlib.pyplot as plt\n\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(\"Device:\", device)\nIMG_SIZE = 64\nTRAIN_PATH = \"../input/iais22-birds/birds/birds\"\nTEST_PATH= \"../input/iais22-birds/submission_test/submission_test\"\nCLASSES = 400\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-06-27T08:52:10.256003Z","iopub.execute_input":"2022-06-27T08:52:10.256793Z","iopub.status.idle":"2022-06-27T08:52:20.387804Z","shell.execute_reply.started":"2022-06-27T08:52:10.256691Z","shell.execute_reply":"2022-06-27T08:52:20.386715Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# DEFINICIÓN DE LA CNN","metadata":{}},{"cell_type":"markdown","source":"Procedemos a implementar la Red Neuronal Convolucional descrita en nuestro artículo *NOTA: Tras la defensa, se realizaron cambios en las capas nn.Linear añadiendo una más y ajustando mejor los valores de sus entradas y salidas.","metadata":{}},{"cell_type":"code","source":"class BirdsModel(pl.LightningModule):\n    def __init__(self):\n      #image_size = 64\n        super().__init__()\n        self.cnv = nn.Conv2d(3,128,5,4)\n        self.rel = nn.ReLU()\n        self.bn = nn.BatchNorm2d(128)\n        self.mxpool = nn.MaxPool2d(4)\n        self.flat = nn.Flatten()\n        self.fc1 = nn.Linear(1152,1712)\n        self.fc2 = nn.Linear(1712,1024)\n        self.fc3 = nn.Linear(1024,756)\n        self.fc4 = nn.Linear(756,CLASSES)\n        self.softmax = nn.Softmax()\n        self.accuracy = metrics.Accuracy()\n\n    def forward(self,x):\n        out = self.cnv(x)\n        out = self.rel(out)\n        out = self.bn(out)\n        out = self.mxpool(out)\n        out = self.flat(out)\n        out = self.rel(self.fc1(out))\n        out = self.rel(self.fc2(out))\n        out = self.rel(self.fc3(out))\n        out = self.fc4(out)\n        return out\n\n    def loss_fn(self,out,target):\n        return nn.CrossEntropyLoss()(out.view(-1,CLASSES),target)\n    \n    def configure_optimizers(self):\n        LR = 1e-3\n        optimizer = torch.optim.AdamW(self.parameters(),lr=LR)\n        return optimizer\n    \n    def predict(self, x):\n        with torch.no_grad():\n            y_hat = self(x)\n            return torch.argmax(y_hat, axis=1)\n\n    def training_step(self,batch,batch_idx):\n        x,y = batch\n        imgs = x.view(-1,3,IMG_SIZE,IMG_SIZE)\n        labels = y.view(-1)\n        out = self(imgs)\n        loss = self.loss_fn(out,labels)\n        out = nn.Softmax(-1)(out)\n        logits = torch.argmax(out,dim=1)\n        accu = self.accuracy(logits, labels)\n        self.log('train_loss', loss, prog_bar=True)\n        self.log('acc', accu, prog_bar=True)\n        return loss       \n\n    def validation_step(self,batch,batch_idx):\n        x,y = batch\n        imgs = x.view(-1,3,IMG_SIZE,IMG_SIZE)\n        labels = y.view(-1)\n        out = self(imgs)\n        loss = self.loss_fn(out,labels)\n        out = nn.Softmax(-1)(out) \n        logits = torch.argmax(out,dim=1)\n        accu = self.accuracy(logits, labels)\n        self.log('valid_loss', loss, prog_bar=True)\n        self.log('train_acc_step', accu, prog_bar=True)\n        return loss, accu\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T08:52:20.390301Z","iopub.execute_input":"2022-06-27T08:52:20.391393Z","iopub.status.idle":"2022-06-27T08:52:20.409133Z","shell.execute_reply.started":"2022-06-27T08:52:20.391353Z","shell.execute_reply":"2022-06-27T08:52:20.408107Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Obtengo el dataset de imágenes\nAdemás aplico transformaciones para ayudar al entrenamiento de la CNN","metadata":{}},{"cell_type":"code","source":"train_transform = torchvision.transforms.Compose([torchvision.transforms.Resize((64,64)),\n                                      torchvision.transforms.ToTensor(),\n                                      torchvision.transforms.Normalize([0.4740, 0.4676, 0.4134], [0.2143, 0.2085, 0.2333])\n                                     ])\ndataset=torchvision.datasets.ImageFolder(root=TRAIN_PATH,transform=train_transform)\ntrain_dataset,val_dataset = torch.utils.data.random_split(dataset,[48000,10388])\ntrain_loader= torch.utils.data.DataLoader(train_dataset,batch_size=512,shuffle=True, pin_memory=True, num_workers=2)\nval_loader= torch.utils.data.DataLoader(val_dataset,batch_size=256, num_workers=2)\nbatch=next(iter(train_loader))\nimgs, labels= batch[0].to(device),batch[1].to(device)\nimgs.shape, labels.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-27T08:52:20.410935Z","iopub.execute_input":"2022-06-27T08:52:20.411866Z","iopub.status.idle":"2022-06-27T08:52:37.231665Z","shell.execute_reply.started":"2022-06-27T08:52:20.411827Z","shell.execute_reply":"2022-06-27T08:52:37.230593Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"mod = BirdsModel().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T08:52:37.234920Z","iopub.execute_input":"2022-06-27T08:52:37.235243Z","iopub.status.idle":"2022-06-27T08:52:37.392139Z","shell.execute_reply.started":"2022-06-27T08:52:37.235217Z","shell.execute_reply":"2022-06-27T08:52:37.390562Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Entrenando el modelo","metadata":{}},{"cell_type":"code","source":"trainer = pl.Trainer(accelerator='gpu',\n                     gpus=1 if str(device)==\"cuda:0\" else 0,\n                     max_epochs=10\n                    \n)\ntrainer.fit(mod,train_loader,val_loader) ","metadata":{"execution":{"iopub.status.busy":"2022-06-27T08:52:37.397412Z","iopub.execute_input":"2022-06-27T08:52:37.399936Z","iopub.status.idle":"2022-06-27T09:09:12.273231Z","shell.execute_reply.started":"2022-06-27T08:52:37.399897Z","shell.execute_reply":"2022-06-27T09:09:12.271831Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"state_dict = mod.state_dict()\n\n# torch.save(object, filename). For the filename, any extension can be used\ntorch.save(state_dict, \"bird_cnn.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:09:28.900029Z","iopub.execute_input":"2022-06-27T09:09:28.900708Z","iopub.status.idle":"2022-06-27T09:09:28.949795Z","shell.execute_reply.started":"2022-06-27T09:09:28.900671Z","shell.execute_reply":"2022-06-27T09:09:28.948541Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# CARGAR MODELO Y PREDECIR\n","metadata":{}},{"cell_type":"markdown","source":"Preparación del submission.csv","metadata":{}},{"cell_type":"code","source":"test_transform = torchvision.transforms.Compose([torchvision.transforms.Resize((64,64)),\n                                      torchvision.transforms.ToTensor(),\n                                      torchvision.transforms.Normalize([0.4740, 0.4676, 0.4134], [0.2143, 0.2085, 0.2333])\n                                     ])\n\n#CustomDataset creado para realizar las predicciones, utiliza un listado con todas las rutas de cada imagen del conjunto de test\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, list_IDs):\n        \n        self.list_IDs = list_IDs\n\n    def __len__(self):\n        \n        return len(self.list_IDs)\n\n    def __getitem__(self, index):\n        \n        # Select sample\n        ID = self.list_IDs[index]\n\n        # Load data\n        img = Image.open(ID)\n        X = test_transform(img).unsqueeze(0)\n\n\n        return X","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:09:52.447419Z","iopub.execute_input":"2022-06-27T09:09:52.447777Z","iopub.status.idle":"2022-06-27T09:09:52.458130Z","shell.execute_reply.started":"2022-06-27T09:09:52.447745Z","shell.execute_reply":"2022-06-27T09:09:52.456801Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"classes=[]\nids=[]\ntest_image_paths = []","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:09:55.364985Z","iopub.execute_input":"2022-06-27T09:09:55.365831Z","iopub.status.idle":"2022-06-27T09:09:55.370729Z","shell.execute_reply.started":"2022-06-27T09:09:55.365778Z","shell.execute_reply":"2022-06-27T09:09:55.369420Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"classes = os.listdir(TRAIN_PATH)\nids = os.listdir(TEST_PATH)\n\nfor data_path in glob.glob(TEST_PATH + '/*'):\n    test_image_paths.append(data_path)\n\ntest_dataset=Dataset(test_image_paths)\nclasses=sorted(classes)\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:10:00.673814Z","iopub.execute_input":"2022-06-27T09:10:00.674342Z","iopub.status.idle":"2022-06-27T09:10:00.692469Z","shell.execute_reply.started":"2022-06-27T09:10:00.674297Z","shell.execute_reply":"2022-06-27T09:10:00.691325Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"state_dict = torch.load(\"./bird_cnn.pth\")\n\nnew_model =BirdsModel()\nnew_model.load_state_dict(state_dict)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:10:07.847424Z","iopub.execute_input":"2022-06-27T09:10:07.847800Z","iopub.status.idle":"2022-06-27T09:10:07.909459Z","shell.execute_reply.started":"2022-06-27T09:10:07.847767Z","shell.execute_reply":"2022-06-27T09:10:07.908158Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_loader= torch.utils.data.DataLoader(test_dataset,batch_size=2000, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:10:10.108837Z","iopub.execute_input":"2022-06-27T09:10:10.109221Z","iopub.status.idle":"2022-06-27T09:10:10.114530Z","shell.execute_reply.started":"2022-06-27T09:10:10.109187Z","shell.execute_reply":"2022-06-27T09:10:10.113529Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"batch=next(iter(test_loader))\nimgs = batch\ntest_imgs = torch.squeeze(imgs, 1)\ntest_imgs.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:10:12.149635Z","iopub.execute_input":"2022-06-27T09:10:12.149994Z","iopub.status.idle":"2022-06-27T09:10:18.107731Z","shell.execute_reply.started":"2022-06-27T09:10:12.149963Z","shell.execute_reply":"2022-06-27T09:10:18.106500Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"outputs = new_model(test_imgs)\n_, predicted = torch.max(outputs, 1)\npred_classes=[]\nfor index in predicted:\n    pred_classes.append(classes[index])\n    \nprint('Predicted: ', ' '.join(f'{predicted[j]:5d}' for j in range(2000)))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:10:19.692582Z","iopub.execute_input":"2022-06-27T09:10:19.692956Z","iopub.status.idle":"2022-06-27T09:10:21.008847Z","shell.execute_reply.started":"2022-06-27T09:10:19.692921Z","shell.execute_reply":"2022-06-27T09:10:21.007886Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"ids_replace=[]\nfor id in ids:\n    ids_replace.append(id.replace('.jpg',''))\ndic={'Id':ids_replace,'Category':pred_classes}\ndf=pd.DataFrame(data=dic)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:10:25.215471Z","iopub.execute_input":"2022-06-27T09:10:25.215824Z","iopub.status.idle":"2022-06-27T09:10:25.233488Z","shell.execute_reply.started":"2022-06-27T09:10:25.215792Z","shell.execute_reply":"2022-06-27T09:10:25.231311Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T09:10:28.412316Z","iopub.execute_input":"2022-06-27T09:10:28.412661Z","iopub.status.idle":"2022-06-27T09:10:28.424952Z","shell.execute_reply.started":"2022-06-27T09:10:28.412632Z","shell.execute_reply":"2022-06-27T09:10:28.423835Z"},"trusted":true},"execution_count":29,"outputs":[]}]}